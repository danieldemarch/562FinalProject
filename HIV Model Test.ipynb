{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danieldemarchi/anaconda3/envs/deepchem/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Generative Adversarial Networks.\"\"\"\n",
    "\n",
    "from deepchem.models import TensorGraph\n",
    "from deepchem.models.tensorgraph import layers\n",
    "from collections import Sequence\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import deepchem as dc\n",
    "from deepchem.data.datasets import NumpyDataset # import NumpyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "n_features = 1024\n",
    "hiv_tasks, hiv_datasets, hiv_transformers = dc.molnet.load_hiv(featurizer='ECFP', split='scaffold', reload=True)\n",
    "hiv_train_dataset, hiv_valid_dataset, hiv_test_dataset = hiv_datasets\n",
    "\n",
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "n_features = 1024\n",
    "rhiv_tasks, rhiv_datasets, rhiv_transformers = dc.molnet.load_hiv(featurizer='ECFP', split='random', reload=True)\n",
    "rhiv_train_dataset, rhiv_valid_dataset, rhiv_test_dataset = rhiv_datasets\n",
    "\n",
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woop\n"
     ]
    }
   ],
   "source": [
    "print(\"woop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/danieldemarchi/anaconda3/envs/deepchem/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/danieldemarchi/anaconda3/envs/deepchem/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/danieldemarchi/anaconda3/envs/deepchem/lib/python3.7/site-packages/tensorflow/python/training/checkpoint_management.py:624: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/danieldemarchi/anaconda3/envs/deepchem/lib/python3.7/site-packages/tensorflow/python/training/checkpoint_management.py:624: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.480679180894233"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multitask_model = dc.models.MultitaskClassifier(\n",
    "    1,\n",
    "    n_features,\n",
    "    layer_sizes=[1000],\n",
    "    dropouts=[.25],\n",
    "    learning_rate=0.001,\n",
    "    batch_size=50)\n",
    "multitask_model.fit(hiv_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model\n",
      "computed_metrics: [0.9935353917530889]\n",
      "computed_metrics: [0.753899360670194]\n",
      "computed_metrics: [0.7411160895343674]\n",
      "HIV Train scores\n",
      "{'mean-roc_auc_score': 0.9935353917530889}\n",
      "HIV Validation scores\n",
      "{'mean-roc_auc_score': 0.753899360670194}\n",
      "HIV Test scores\n",
      "{'mean-roc_auc_score': 0.7411160895343674}\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating model\")\n",
    "train_scores = multitask_model.evaluate(hiv_train_dataset, [metric], hiv_transformers)\n",
    "valid_scores = multitask_model.evaluate(hiv_valid_dataset, [metric], hiv_transformers)\n",
    "test_scores = multitask_model.evaluate(hiv_test_dataset, [metric], hiv_transformers)\n",
    "\n",
    "print(\"HIV Train scores\")\n",
    "print(train_scores)\n",
    "\n",
    "print(\"HIV Validation scores\")\n",
    "print(valid_scores)    \n",
    "    \n",
    "print(\"HIV Test scores\")\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_model = dc.models.ProgressiveMultitaskClassifier(\n",
    "    1,\n",
    "    n_features,\n",
    "    layer_sizes=[1000],\n",
    "    dropouts=[.25],\n",
    "    learning_rate=0.001,\n",
    "    batch_size=50)\n",
    "prog_model.fit(hiv_train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model\n",
      "computed_metrics: [0.9954860810666172]\n",
      "computed_metrics: [0.7482975700568293]\n",
      "computed_metrics: [0.7406366480619556]\n",
      "HIV Train scores\n",
      "{'mean-roc_auc_score': 0.9954860810666172}\n",
      "HIV Validation scores\n",
      "{'mean-roc_auc_score': 0.7482975700568293}\n",
      "HIV Test scores\n",
      "{'mean-roc_auc_score': 0.7406366480619556}\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating model\")\n",
    "train_scores = prog_model.evaluate(hiv_train_dataset, [metric], hiv_transformers)\n",
    "valid_scores = prog_model.evaluate(hiv_valid_dataset, [metric], hiv_transformers)\n",
    "test_scores = prog_model.evaluate(hiv_test_dataset, [metric], hiv_transformers)\n",
    "\n",
    "print(\"HIV Train scores\")\n",
    "print(train_scores)\n",
    "\n",
    "print(\"HIV Validation scores\")\n",
    "print(valid_scores)    \n",
    "    \n",
    "print(\"HIV Test scores\")\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.554179872050502"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robust_model = dc.models.RobustMultitaskClassifier(\n",
    "    1,\n",
    "    n_features,\n",
    "    layer_sizes=[1000],\n",
    "    dropouts=[.25],\n",
    "    learning_rate=0.001,\n",
    "    batch_size=50)\n",
    "robust_model.fit(hiv_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model\n",
      "computed_metrics: [0.9959683421823053]\n",
      "computed_metrics: [0.7495652067411327]\n",
      "computed_metrics: [0.7474299426408391]\n",
      "HIV Train scores\n",
      "{'mean-roc_auc_score': 0.9959683421823053}\n",
      "HIV Validation scores\n",
      "{'mean-roc_auc_score': 0.7495652067411327}\n",
      "HIV Test scores\n",
      "{'mean-roc_auc_score': 0.7474299426408391}\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating model\")\n",
    "train_scores = robust_model.evaluate(hiv_train_dataset, [metric], hiv_transformers)\n",
    "valid_scores = robust_model.evaluate(hiv_valid_dataset, [metric], hiv_transformers)\n",
    "test_scores = robust_model.evaluate(hiv_test_dataset, [metric], hiv_transformers)\n",
    "\n",
    "print(\"HIV Train scores\")\n",
    "print(train_scores)\n",
    "\n",
    "print(\"HIV Validation scores\")\n",
    "print(valid_scores)    \n",
    "    \n",
    "print(\"HIV Test scores\")\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to initialize singletask to multitask model\n",
      "Initializing directory for task HIV_active\n",
      "About to create task-specific datasets\n",
      "Splitting multitask dataset into singletask datasets\n",
      "TIMING: dataset construction took 0.005 s\n",
      "Loading dataset from disk.\n",
      "Processing shard 0\n",
      "\tTask HIV_active\n",
      "Processing shard 1\n",
      "\tTask HIV_active\n",
      "Processing shard 2\n",
      "\tTask HIV_active\n",
      "Processing shard 3\n",
      "\tTask HIV_active\n",
      "Processing shard 4\n",
      "\tTask HIV_active\n",
      "Processing shard 5\n",
      "\tTask HIV_active\n",
      "Dataset for task HIV_active has shape ((32901, 1024), (32901, 1), (32901, 1), (32901,))\n",
      "Fitting model for task HIV_active\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danieldemarchi/anaconda3/envs/deepchem/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model\n",
      "computed_metrics: [0.929515587470725]\n",
      "computed_metrics: [0.7572766632373114]\n",
      "Train scores\n",
      "{'mean-roc_auc_score': 0.929515587470725}\n",
      "Validation scores\n",
      "{'mean-roc_auc_score': 0.7572766632373114}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import deepchem as dc\n",
    "from deepchem.molnet import load_tox21\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def model_builder(model_dir_logreg):\n",
    "  sklearn_model = LogisticRegression(\n",
    "      penalty=\"l2\", C=1. / 0.05, class_weight=\"balanced\", n_jobs=-1)\n",
    "  return dc.models.sklearn_models.SklearnModel(sklearn_model, model_dir_logreg)\n",
    "\n",
    "\n",
    "log_model = dc.models.multitask.SingletaskToMultitask(hiv_tasks, model_builder)\n",
    "\n",
    "# Fit trained model\n",
    "log_model.fit(hiv_train_dataset)\n",
    "\n",
    "print(\"Evaluating model\")\n",
    "train_scores = log_model.evaluate(hiv_train_dataset, [metric], hiv_transformers)\n",
    "valid_scores = log_model.evaluate(hiv_valid_dataset, [metric], hiv_transformers)\n",
    "\n",
    "print(\"Train scores\")\n",
    "print(train_scores)\n",
    "\n",
    "print(\"Validation scores\")\n",
    "print(valid_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "multicorrect = multitask_model.predict(hiv_test_dataset, hiv_transformers)[:, 0][:,1]\n",
    "progcorrect = prog_model.predict(hiv_test_dataset, hiv_transformers)[:, 0][:,1]\n",
    "robcorrect = robust_model.predict(hiv_test_dataset, hiv_transformers)[:, 0][:,1]\n",
    "logcorrect = log_model.predict(hiv_test_dataset, hiv_transformers)[:, 0][:,1]\n",
    "\n",
    "rprogcorrect = np.rint(progcorrect)\n",
    "rrobcorrect = np.rint(robcorrect)\n",
    "rmulticorrect = np.rint(multicorrect)\n",
    "rlogcorrect = np.rint(logcorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiprog = np.logical_and(rmulticorrect, rprogcorrect)\n",
    "multirob = np.logical_and(rmulticorrect, rrobcorrect)\n",
    "multilog = np.logical_and(rmulticorrect, rlogcorrect)\n",
    "\n",
    "progrob = np.logical_and(rprogcorrect, rrobcorrect)\n",
    "proglog = np.logical_and(rprogcorrect, rlogcorrect)\n",
    "\n",
    "roblog = np.logical_and(rrobcorrect, rlogcorrect)\n",
    "\n",
    "every = np.logical_and(multiprog, multirob)\n",
    "every = np.logical_and(every, multirob)\n",
    "every = np.logical_and(every, multilog)\n",
    "\n",
    "every = np.logical_and(every, progrob)\n",
    "every = np.logical_and(every, proglog)\n",
    "\n",
    "every = np.logical_and(every, roblog)\n",
    "\n",
    "every2 = np.logical_and(multiprog, multirob)\n",
    "every2 = np.logical_and(every2, multirob)\n",
    "\n",
    "every2 = np.logical_and(every2, progrob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multitask 99\n",
      "Progressive 175\n",
      "Robust 204\n",
      "LogModel 797\n",
      "Intersection of models\n",
      "79\n",
      "78\n",
      "83\n",
      "121\n",
      "137\n",
      "161\n",
      "All of them\n",
      "62\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "print(\"Multitask\", np.count_nonzero(rmulticorrect))\n",
    "print(\"Progressive\", np.count_nonzero(rprogcorrect))\n",
    "print(\"Robust\", np.count_nonzero(rrobcorrect))\n",
    "print(\"LogModel\", np.count_nonzero(rlogcorrect))\n",
    "print(\"Intersection of models\")\n",
    "print(np.count_nonzero(multiprog))\n",
    "print(np.count_nonzero(multirob))\n",
    "print(np.count_nonzero(multilog))\n",
    "\n",
    "print(np.count_nonzero(progrob))\n",
    "print(np.count_nonzero(proglog))\n",
    "\n",
    "print(np.count_nonzero(roblog))\n",
    "print(\"All of them\")\n",
    "print(np.count_nonzero(every))\n",
    "print(np.count_nonzero(every2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.logical_and(rmulticorrect, hiv_test_dataset.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "463\n",
      "468\n",
      "470\n",
      "685\n",
      "695\n",
      "697\n",
      "698\n",
      "699\n",
      "707\n",
      "740\n",
      "741\n",
      "742\n",
      "801\n",
      "906\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "975\n",
      "977\n",
      "1102\n",
      "1191\n",
      "1192\n",
      "1475\n",
      "3554\n",
      "3774\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "ticker = 0\n",
    "for i in range(0, len(every2)):\n",
    "    if every2[i] == 1:\n",
    "        if hiv_test_dataset.y[i] == 1:\n",
    "            print(i)\n",
    "            ticker+= 1\n",
    "print(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
